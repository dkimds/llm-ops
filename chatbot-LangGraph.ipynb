{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a support chatbot in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os \n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a basic chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Type of messages: list\n",
    "    # `add_messages`: how this state key should be updated\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Node\n",
    "    - INPUT: the current State\n",
    "    - OUTPUT: a value that updates the state\n",
    "2. messages\n",
    "    - appended to the current list\n",
    "    - communicated via `add_messages` in `Annotated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return{\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 1st arg: unique node name\n",
    "# 2nd arg: function or object called whenever the node's used\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`entry`: Where to start its work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`finish`: any time this node is run, you can exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CompiledGraph`: we can use invoke on our state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # (Optional) extra dependecies\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I couldn't find any information on \"langgraph.\" It's possible that it's a misspelling, a made-up word, or something very niche.\n",
      "\n",
      "However, I can think of a few possibilities:\n",
      "\n",
      "1. **Language graph**: This could be a concept in linguistics or computer science related to visualizing language data, such as the structure and relationships between words, concepts, or entities.\n",
      "2. **LanguagE Graph**: A more plausible interpretation is that langgraph is an abbreviation for \"language engineering graph,\" which might refer to a framework or tool for representing and analyzing linguistic information in a graphical format.\n",
      "\n",
      "If none of these possibilities resonate with you, could you please provide more context about where you heard of langgraph? I'd be happy to try and help clarify what it's all about!\n",
      "Assistant: It seems that you forgot to ask a question or provide any context for our conversation. I'd be happy to chat with you, but I need something to respond to.\n",
      "\n",
      "If you're ready, we can start fresh and explore a topic of your choice. What's on your mind?\n",
      "Assistant: It seems like we've gotten off to a bit of a confusing start. I'm happy to try and help you clarify what's on your mind, though!\n",
      "\n",
      "Can you tell me more about what \"that\" is that doesn't seem right? Is there something specific that's bothering you or causing concern?\n",
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enhencing the Chatbot with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n",
       "  'content': 'Nodes¶ In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id). Similar to NetworkX, you add these nodes to a graph using the add_node method:'},\n",
       " {'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48',\n",
       "  'content': 'Each node in a LangGraph graph has the ability to access, read, and write to the state. When a node modifies the state, it effectively broadcasts this information to all other nodes within the graph .'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The same as in Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    message: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BasicToolNode`\n",
    "- checkts the most recent message in the state and calls tools if the message contains `tool_calls`.\n",
    "- relies on the LLM's `tool_calling` support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`route_tools`: checks for tool_calls in the chatbot's output.\n",
    "`add_conditional_edges`: tells the graph that whenever the `chatbot` ndoe completes to check this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice** that conditional edges start from a single node. This tells the graph \"any time the 'chatbot' node runs, either go to 'tools' if it calls a tool, or end the loop if it responds directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Must write to at least one of ['message']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_input)]}):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], BaseMessage):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1221\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1216\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1217\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1218\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1219\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1220\u001b[0m ):\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1222\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1223\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1224\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1225\u001b[0m     ):\n\u001b[1;32m   1226\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   1228\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/runner.py:85\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, timeout, retry_policy)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m _panic_or_proceed(all_futures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/runner.py:186\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, timeout_exc_cls)\u001b[0m\n\u001b[1;32m    184\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/executor.py:59\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         task\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphInterrupt:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/retry.py:26\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     24\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, task\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:121\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    120\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 121\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    123\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/write.py:86\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     writes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     81\u001b[0m         ChannelWriteEntry(write\u001b[38;5;241m.\u001b[39mchannel, \u001b[38;5;28minput\u001b[39m, write\u001b[38;5;241m.\u001b[39mskip_none, write\u001b[38;5;241m.\u001b[39mmapper)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m write\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrites\n\u001b[1;32m     85\u001b[0m     ]\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_write(\n\u001b[1;32m     87\u001b[0m         config,\n\u001b[1;32m     88\u001b[0m         writes,\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_at_least_one_of \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/langgraph/pregel/write.py:139\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[0;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m require_at_least_one_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m {chan \u001b[38;5;28;01mfor\u001b[39;00m chan, _ \u001b[38;5;129;01min\u001b[39;00m filtered} \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(require_at_least_one_of):\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust write to at least one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequire_at_least_one_of\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         )\n\u001b[1;32m    142\u001b[0m write: TYPE_SEND \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m][CONFIG_KEY_SEND]\n\u001b[1;32m    143\u001b[0m write(sends \u001b[38;5;241m+\u001b[39m filtered)\n",
      "\u001b[0;31mInvalidUpdateError\u001b[0m: Must write to at least one of ['message']"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
