{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Local RAG Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Document loading, retrieval methods and text splitting\n",
    "%pip install -qU langchain langchain_community\n",
    "\n",
    "# Local vector store via Chroma\n",
    "%pip install -qU langchain_chroma\n",
    "\n",
    "# Local inference and embeddings via Ollama\n",
    "%pip install -qU langchain_ollama\n",
    "\n",
    "# Web Loader\n",
    "%pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The scene is set: A dark, crowded comedy club. The audience is on the edge of their seats as two comedic heavyweights face off in the ultimate rap battle showdown. In the blue corner, we have Stephen Colbert, aka \"The O'Reilly Factor's\" erstwhile host. And in the red corner, it's John Oliver, the biting satirist from Last Week Tonight. Let's get ready to rumble!**\n",
      "\n",
      "**Round 1: Stephen Colbert**\n",
      "(Speaking confidently)\n",
      "Yo, I'm the king of late-night TV fame,\n",
      "From The Daily Show to this comedy game.\n",
      "My wit is sharp, my satire's tight,\n",
      "I take on politics with all my might.\n",
      "\n",
      "**(Colbert starts rapping)**\n",
      "\n",
      "I'm not a pundit, no Fox in me,\n",
      "Just a satirist, with sarcasm as my decree.\n",
      "I skewer the right, and sometimes the left,\n",
      "My words are truth, don't get it twisted, I'm correct!\n",
      "\n",
      "**Round 1: John Oliver**\n",
      "(Speaking with a hint of amusement)\n",
      "Hold up, Stephen, let's not get ahead,\n",
      "Your time at The Daily Show was quite... well-bred.\n",
      "But since then, you've been playing the fool,\n",
      "A conservative, trying to make your point cool.\n",
      "\n",
      "**(Oliver starts rapping)**\n",
      "\n",
      "My show's a fact-checker, no pretender here,\n",
      "Just facts and figures, no spin or fear.\n",
      "I take on corruption, and the powerful too,\n",
      "You're just a relic of the 2000s crew!\n",
      "\n",
      "**Round 2: Stephen Colbert**\n",
      "(Laughing)\n",
      "John, John, always quick to fire,\n",
      "But your facts are weak, your arguments retire.\n",
      "You may be smart, but your humor's dull,\n",
      "Just a monotone voice, trying to sound cool.\n",
      "\n",
      "**(Colbert starts rapping)**\n",
      "\n",
      "My show was edgy, yours is just the same,\n",
      " Same old criticism, no real game.\n",
      "I pushed the envelope, made people think,\n",
      "Your Last Week Tonight's just a lukewarm sink!\n",
      "\n",
      "**Round 2: John Oliver**\n",
      "(Smiling)\n",
      "Stephen, Stephen, so quick to attack,\n",
      "But your ego's inflated, like a balloon that'll crack.\n",
      "You may have fooled some with your right-wing guise,\n",
      "But we know the truth, you're just another corporate surprise.\n",
      "\n",
      "**(Oliver starts rapping)**\n",
      "\n",
      "My show's got heart, and it's always on point,\n",
      "Facts, not fiction, no partisan joint.\n",
      "I expose corruption, in all its forms,\n",
      "While you're stuck in the past, with your outdated norms!\n",
      "\n",
      "**The crowd goes wild!**\n",
      "The rap battle is intense, each comedian trying to outdo the other. In the end, it's a close call, but John Oliver might have just won over the audience... or has he? The debate will continue.\n",
      "\n",
      "What do you think, folks? Who won this epic rap battle?\n"
     ]
    }
   ],
   "source": [
    "response_message = model.invoke(\n",
    "    \"Simulate a rap battle between Stephen Colbert and John Oliver\"\n",
    ")\n",
    "\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes in these retrieved documents appear to be:\\n\\n1. **Task Decomposition**: Breaking down complex tasks into smaller, manageable subgoals, which can be achieved through various methods such as:\\n\\t* Using Large Language Models (LLM) with simple prompting\\n\\t* Utilizing task-specific instructions\\n\\t* Incorporating human inputs\\n2. **Planning and Execution**: A system or agent that can plan ahead, execute specific tasks, and log results efficiently.\\n3. **Autonomous Agent System**: An overview of a system powered by LLMs, which involves multiple components, including:\\n\\t* Planning: Breaking down complex tasks into smaller subgoals and planning ahead\\n\\t* Task Execution: Expert models executing on specific tasks and logging results\\n4. **Self-Improvement**: The ability of an agent to reflect on past actions, learn from mistakes, and refine them for future steps, leading to improved quality in final results.\\n\\nThese themes seem to be related to the development of autonomous systems powered by Large Language Models (LLMs), which can perform complex tasks efficiently by breaking them down into smaller subgoals and executing specific tasks.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "# Docu -> Str by concat and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are three approaches to Task Decomposition: (1) using Large Language Models (LLM) with simple prompting, (2) using task-specific instructions, and (3) with human inputs. These approaches help break down large tasks into smaller, manageable subgoals for efficient handling. This process enables the agent to plan ahead and improve the quality of final results through reflection and refinement.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A with retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = (\n",
    "    {\"context\": retriever| format_docs, \"question\": RunnablePassthrough()}\n",
    "    |rag_prompt\n",
    "    |model\n",
    "    |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition can be done through three approaches: (1) using Large Language Models (LLM) with simple prompting, (2) utilizing task-specific instructions, and (3) receiving human inputs. This allows agents to break down complex tasks into manageable subgoals.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
